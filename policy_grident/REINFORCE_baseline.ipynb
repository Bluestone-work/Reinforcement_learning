{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tool import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03921332,  0.01333219, -0.03220644,  0.04860539], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = MyWrapper()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_action(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_action, self).__init__()\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 2),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "            \n",
    "    def forward(self, state):\n",
    "        return self.fc(state)\n",
    "\n",
    "class Model_baseline(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_baseline, self).__init__()\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, state):\n",
    "        return self.fc(state)\n",
    "\n",
    "model_action = Model_action()\n",
    "model_baseline = Model_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-973.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import random\n",
    "\n",
    "\n",
    "#玩一局游戏并记录数据\n",
    "def play(show=False):\n",
    "    state = []\n",
    "    action = []\n",
    "    reward = []\n",
    "\n",
    "    s = env.reset()\n",
    "    o = False\n",
    "    while not o:\n",
    "        #根据概率采样\n",
    "        prob = model_action(torch.FloatTensor(s).reshape(1, 4))[0].tolist()\n",
    "        a = random.choices(range(2), weights=prob, k=1)[0]\n",
    "\n",
    "        ns, r, o = env.step(a)\n",
    "\n",
    "        state.append(s)\n",
    "        action.append(a)\n",
    "        reward.append(r)\n",
    "\n",
    "        s = ns\n",
    "\n",
    "        if show:\n",
    "            display.clear_output(wait=True)\n",
    "            env.show()\n",
    "\n",
    "    state = torch.FloatTensor(state).reshape(-1, 4)\n",
    "    action = torch.LongTensor(action).reshape(-1, 1)\n",
    "    reward = torch.FloatTensor(reward).reshape(-1, 1)\n",
    "\n",
    "    return state, action, reward, reward.sum().item()\n",
    "\n",
    "\n",
    "state, action, reward, reward_sum = play()\n",
    "\n",
    "reward_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_action = torch.optim.Adam(model_action.parameters(), lr=5e-3)\n",
    "optimizer_baseline = torch.optim.Adam(model_baseline.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, action, reward, reward_sum = play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_value(reward):\n",
    "    #计算当前state的价值,其实就是Q(state,action),这里是用蒙特卡洛法估计的\n",
    "    value = []\n",
    "    for i in range(len(reward)):\n",
    "        s = 0\n",
    "        for j in range(i, len(reward)):\n",
    "            s += reward[j] * 0.99**(j - i)\n",
    "        value.append(s)\n",
    "\n",
    "    return torch.FloatTensor(value).reshape(-1, 1)\n",
    "\n",
    "\n",
    "value = get_value(reward)\n",
    "\n",
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练baseline模型\n",
    "def train_baseline(state, value):\n",
    "    baseline = model_baseline(state)\n",
    "\n",
    "    loss = torch.nn.functional.mse_loss(baseline, value)\n",
    "    loss.backward()\n",
    "    optimizer_baseline.step()\n",
    "    optimizer_baseline.zero_grad()\n",
    "\n",
    "    return baseline.detach()\n",
    "\n",
    "\n",
    "baseline = train_baseline(state, value)\n",
    "\n",
    "baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-527.9689331054688"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练action模型\n",
    "def train_action(state, action, value, baseline):\n",
    "    #重新计算动作的概率\n",
    "    prob = model_action(state).gather(dim=1, index=action)\n",
    "\n",
    "    #求Q最大的导函数 -> partial value / partial action\n",
    "    #注意这里的Q使用前要去基线,这也是baseline模型存在的意义\n",
    "    prob = (prob + 1e-8).log() * (value - baseline)\n",
    "    for i in range(len(prob)):\n",
    "        prob[i] = prob[i] * 0.99**i\n",
    "    loss = -prob.mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_action.step()\n",
    "    optimizer_action.zero_grad()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_action(state, action, value, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -548.5003662109375 -982.85\n",
      "100 -471.5755615234375 -964.05\n",
      "200 -199.2019805908203 -846.85\n",
      "300 18.61717987060547 92.85\n",
      "400 18.147506713867188 200.0\n",
      "500 19.621679306030273 200.0\n",
      "600 19.137928009033203 200.0\n",
      "700 17.834165573120117 142.25\n",
      "800 19.338045120239258 200.0\n",
      "900 16.320999145507812 200.0\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "def train():\n",
    "    model_action.train()\n",
    "    model_baseline.train()\n",
    "\n",
    "    #训练N局\n",
    "    for epoch in range(1000):\n",
    "        #玩一局游戏,得到数据\n",
    "        state, action, reward, _ = play()\n",
    "        #训练两个模型\n",
    "        value = get_value(reward)\n",
    "        baseline = train_baseline(state, value)\n",
    "        loss = train_action(state, action, value, baseline)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            test_result = sum([play()[-1] for _ in range(20)]) / 20\n",
    "            print(epoch, loss, test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(True)[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
