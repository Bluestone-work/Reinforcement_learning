{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torch.utils.tensorboard import SummaryWriter  # 导入SummaryWriter\n",
    "\n",
    "import grid_env\n",
    "from model import *\n",
    "from render import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = grid_env.GridEnv(size=2, target=[1, 1], forbidden=[[1, 0]],render_mode='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我有一个Vk，当这个Vk还没有收敛的时候(收敛的情况就是Vk-Vk-1他还没有说小于一个很小的值)，我们就做下面的事：\n",
    "假设这是第k次的iteration，首先我们遍历所有的状态s，然后对于所有的状态s，我们遍历它所有的action，计算出来每一个s对应的action的这个qk，这里 $$qk = \\sum_r p(r \\mid s, a) r + \\gamma \\sum_{s'} p(s' \\mid s, a) v_k(s')$$\n",
    "首先，我们要看到哪一个action对应的是最大的qk，然后policy update就是选择这个action。value update就是这个最大的qk.$$ Vk+1 = maxaQk(a,s) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, theta = 0.0001, gamma = 0.8, steps=100):\n",
    "    state_space_size = env.size ** 2\n",
    "    action_space_size = env.action_space_size\n",
    "    reward_list = env.reward_list\n",
    "    reward_space_size = len(reward_list)\n",
    "    \n",
    "    # 初始化状态值函数\n",
    "    state_value_k = np.zeros(shape=(state_space_size))  # 初始化状态值函数为全零的数组，形状为 (state_space_size)，记录每个状态的值。\n",
    "    policy = np.zeros(shape=(state_space_size, action_space_size))  # 初始化策略\n",
    "    \n",
    "    for step in range(steps):\n",
    "        delta = 0  # 用于记录状态值更新的最大变化\n",
    "        \n",
    "        # 遍历每一个状态\n",
    "        for state in range(state_space_size):\n",
    "            qvalue_list = []\n",
    "            \n",
    "            # 遍历每一个动作，计算每个动作的Q值\n",
    "            for action in range(action_space_size):\n",
    "                qvalue = 0\n",
    "                \n",
    "                # 累加奖励\n",
    "                for i in range(reward_space_size):\n",
    "                    qvalue += reward_list[i] * env.Rsa[state, action, i]\n",
    "                \n",
    "                # 累加未来状态值的折扣回报\n",
    "                for next_state in range(state_space_size):\n",
    "                    qvalue += gamma * env.Psa[state, action, next_state] * state_value_k[next_state]\n",
    "                \n",
    "                qvalue_list.append(qvalue)\n",
    "            \n",
    "            # 更新状态值函数\n",
    "            best_qvalue = max(qvalue_list)\n",
    "            delta = max(delta, np.abs(best_qvalue - state_value_k[state]))\n",
    "            state_value_k[state] = best_qvalue\n",
    "            \n",
    "            # 选择最优动作并更新策略\n",
    "            best_action = np.argmax(qvalue_list)\n",
    "            policy[state] = np.eye(action_space_size)[best_action]\n",
    "        \n",
    "        # 检查是否满足收敛条件\n",
    "        if delta < theta:\n",
    "            print(f\"Converged after {step + 1} steps.\")\n",
    "            break\n",
    "    \n",
    "    return policy, state_value_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 43 steps.\n"
     ]
    }
   ],
   "source": [
    "policy , a =value_iteration(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Reinforcement_learning\\scripts\\render.py:153: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 定义动作对应的方向\n",
    "action_to_direction = {\n",
    "    0: np.array([-1, 0]),\n",
    "    1: np.array([0, 1]),\n",
    "    2: np.array([1, 0]),\n",
    "    3: np.array([0, -1]),\n",
    "    4: np.array([0, 0]),\n",
    "}\n",
    "render = Render(target=[1, 1], forbidden=[[1, 0]], size=2)\n",
    "# 绘制每个状态的最优动作\n",
    "for state in range(policy.shape[0]):\n",
    "    # 计算状态在网格中的位置\n",
    "    row, col = env.state2pos(state)\n",
    "    \n",
    "    # 找出当前状态下的最优动作\n",
    "    best_action = np.argmax(policy[state])\n",
    "    \n",
    "    # 根据最优动作绘制箭头\n",
    "    render.draw_action(pos=[row, col], toward=action_to_direction[best_action])\n",
    "\n",
    "# 显示结果\n",
    "render.show_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
