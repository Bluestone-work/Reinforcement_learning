![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010095653.png)


![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010100439.png)
1.方法一：平均分布，我把所有的状态都认为是平等的。我给每个人求平均时候的权重是一样的。
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010100550.png)
这时候的J(w)就是所有的状态误差和在求平方/状态数。
这样设计的话，我们在初始就将所有的状态看做是同等重要的，但实际上可能不是这样的，比如说我们要从某一个状态出发，到达目标状态，那么目标状态和接近目标状态的那些状态他们是更加重要的，而有些远离目标状态的那些状态，他们是没有那么重要的。
我们希望给重要的状态分配比较大的权重，这样他们的误差会比较小。![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010102452.png)

2.方法二：stationary distribution 
long-run behavior 我从某个状态出发，然后我按照一个策略，我采取action，然后不断地去和环境进行交互，然后我一直采取这个策略，采取了非常多次，之后实际上就达到了一种平稳的状态，在那个平稳状态下，能够告诉你在每一个状态他的agent出现的概率是多少。![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010103858.png)
这里的dπ实际上扮演这权重的角色。
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010103950.png)
Stationary 平稳![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010104105.png)
例子：
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010104305.png)
dπs满足如下性质，其中pπs是状态转移矩阵
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010104601.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010104732.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010110230.png)

![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010111048.png)
这个Vπ(St)是我们所不知道的，所以我们要通过别的方法来替代它。
方法一：蒙特卡洛方法。
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010111154.png)
方法二：TD算法
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010111228.png)

### 代码：
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010111328.png)
Vhat 的选择有很多种。最广泛的是两种方法，
方法一：之前使用比较广泛
线性近似，polynomial basis 多项式近似
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010115401.png)
方法二：目前使用比较广泛
神经网络
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010115418.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010115504.png)


虽然linear function不能近似所有函数，但是他还是有很强的表现力的，
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010115716.png)


### 分析table和linear
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010115802.png)
如果把feature vector换成右边那种向量，它实际上就相当于是一个table。我如果把φs带入v(s,w)当中后面就会转化成esTw因为es只有对应s的那个量是1其他全是0，所以最后就等于w(s)。
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010120005.png)
w(s)实际上是向量当中对应状态s的那一个元素。这时候会发现vhat实际上就变成了一个向量，或者说是一个一维的表格，我要去找s所对应的vhat，我就可以直接去这个表格中找。

![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010120231.png)
est只有对应st的位置是=1的其他都是0，所以w当中只有st那个位置被更新了，其他都没动。
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010120344.png)
这个就与之前表格形式的TD算法是一样的，唯一的区别是之前是V现在是W。