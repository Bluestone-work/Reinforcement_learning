![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010120624.png)

### Grand truth
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010122752.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010123435.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010123558.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010123723.png)
越复杂的参数拟合的效果越好
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010123753.png)

通过这些例子可以更好的去理解拟合效果。
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010124021.png)
严格上来说3式是不是在minimize1式。

![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010124131.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010124219.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010124301.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010124320.png)
M投影矩阵

![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010172347.png)


#### function approximation 代码
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010172449.png)
任务是我从一个状态出发，然后我要到目标状态，找到一个好的路径过去。
第一步是要生成数据，我在st的时候要根据策略，然后take action at然后和环境进行交互得到rt+1和st+1。之后再st+1我再看一下在策略π中采取的action是什么。
根据得到的数据我们再Value updata和Policy updata。
值得注意的是，在之前table的情况下，其实我可以直接去索引这个q，现在我们需要去算一下qhat。我们把s和所对应的这个a带到这个函数里面计算一下这个函数值，然后再作比较。

### 例子
这个例子是把Sarsa和linear function approximation结合起来。
qhat是等于φT×w
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20241010175103.png)
